# ANN Basic 
on the nootbook i use () this nootbook to get a better idea the changes that i made where:
- Add new hidden layers to see how accurancy does the model imprpove.
- As well try tanh in the activation function to see the accurancy  of it insted of using the relu activation function .

ANN basic( https://github.com/Omorusi/Neural-network/blob/main/Basic_ANN(Copy).ipynb)
I experimented with the activation function in the basic ANN model from this repository. Initially, the model used ReLU, and I wanted to see how the accuracy would change if I replaced it with Tanh.

Hereâ€™s the accuracy with ReLU:
- this is the accurancy by using relu
   ![image alt](https://github.com/Omorusi/Neural-network/blob/main/Screenshot%202025-03-24%20221323.png?raw=true)
-Accurancy
 ![image alt](https://github.com/Omorusi/Neural-network/blob/main/Screenshot%202025-03-24%20220804.png?raw=true)
This is after using tagh
   ![image alt](https://github.com/Omorusi/Neural-network/blob/main/Screenshot%202025-03-24%20221345.png?raw=true)
  - Accurancy
 ![image alt](https://github.com/Omorusi/Neural-network/blob/main/Screenshot%202025-03-24%20220830.png?raw=true)

# CNN Apple and Tomatoes
-Added more layers to the relu activation to see if the accurancy increase ,current accurancy is 65%.Deeper network: 6 convolutional layers instead of 5.
  ![image alt](https://github.com/Omorusi/Neural-network/blob/main/Screenshot%202025-03-24%20181357.png?raw=true)
- Changed the activation from relu to LeakyReLU to see how accurancy the model will be after it. The accurancy using relu was 78% 
  ![image alt](https://github.com/Omorusi/Neural-network/blob/main/Screenshot%202025-03-24%20175229.png?raw=true)
   ![image alt](https://github.com/Omorusi/Neural-network/blob/main/Screenshot%202025-03-24%20175250.png?raw=true)
- Added another layer to see if the accurancy increase
 ![image alt](https://github.com/Omorusi/Neural-network/blob/main/Screenshot%202025-03-24%20181722.png?raw=true)

#Chapgpt model

